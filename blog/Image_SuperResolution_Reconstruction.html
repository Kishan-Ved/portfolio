<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1CKHTEMMH2"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1CKHTEMMH2");</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Image SuperResolution and Reconstruction | Kishan Ved</title> <meta name="author" content="Kishan Ved"> <meta name="description" content="A Machine Learning Project"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A6%BE&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kishanved.tech//blog/Image_SuperResolution_Reconstruction"> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><b>Kishan Ved</b></a> <div class="navbar-brand social"> | <a href="mailto:%6B%69%73%68%61%6E.%76%65%64@%69%69%74%67%6E.%61%63.%69%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/Kishan-Ved" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/kishan-ved-506140259" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://wa.me/919619319866" title="whatsapp" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-whatsapp"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">GSoC<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/github/">GitHub</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Image SuperResolution and Reconstruction</h1> <p class="post-meta">July 14, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ML</a>     ·   <a href="/blog/category/ml"> <i class="fa-solid fa-tag fa-sm"></i> ML</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="image-super-resolution-and-reconstruction">Image Super Resolution and Reconstruction</h1> <p>Important GitHub links to codes used to create this file:</p> <p>A) <a href="https://github.com/Kishan-Ved/Image-SuperResolution-Reconstruction/blob/main/Image_SuperResolution_Qualitative.ipynb" rel="external nofollow noopener" target="_blank">Qualitative Analysis</a> <span style="font-family: Times New Roman; font-size: 20px;"></span></p> <p>B) <a href="https://github.com/Kishan-Ved/Image-SuperResolution-Reconstruction/blob/main/Image_SuperResolution._Quantitative.ipynb" rel="external nofollow noopener" target="_blank">Quantitative Analysis</a> <span style="font-family: Times New Roman; font-size: 20px;"></span></p> <p>C) <a href="https://github.com/Kishan-Ved/Image-SuperResolution-Reconstruction/blob/main/Image_Reconstruction.ipynb" rel="external nofollow noopener" target="_blank">Image Reconstruction</a> <span style="font-family: Times New Roman; font-size: 20px;"></span></p> <h2 id="super-resolution-using-random-fourier-features-and-linear-regression">Super-Resolution Using Random Fourier Features and Linear Regression</h2> <h3 id="a-qualitative-analysis">$A.$ Qualitative Analysis</h3> <p>The provided code performs Qualitative Analysis of Super-Resolution on a given Image using a Linear Model trained on Random Fourier Features. Here is the breakdown of the code:</p> <ol> <li> <p><strong>Imports:</strong> The necessary libraries such as PyTorch, torchvision, matplotlib, urllib, numpy, sklearn, einops, and warnings are imported. All of these libraries are necessary for the code to run.</p> </li> <li> <p><strong>Loading the Image:</strong> The image of a dog as mentioned in the question is taken form the instructer’s code and read using <code class="language-plaintext highlighter-rouge">torchvision.io.read_image</code> function. The image is then displayed using matplotlib.</p> <div align="center"> <img src="./Ques4Img/ori_dog.png" alt="dog_img" width="80%"> </div> <p>+</p> </li> <li> <p><strong>Scaling the RGB Values:</strong> The RGB values of the image are scaled from 0 to 1 using Min-Max scaler from the sklearn.preprocessing module. The formula for scaling the RGB values is given by:</p> <p><strong>[ X_{scaled} = \frac{X_{max}-X}{X_{max}-X_{min}} ]</strong><br> where ( X_{max} ) and ( X_{min} ) are the maximum and minimum values of the RGB channels, respectively.</p> </li> <li> <p><strong>Cropping the Image:</strong> Due to the memory constraints, the size of the target image we took is 100 x 100. The image is cropped to this size using the <code class="language-plaintext highlighter-rouge">torchvision.transforms.functional.crop</code> function.</p> <div align="center"> <img src="./Ques4Img/dog100.png" alt="dog_img" width="60%"> </div> <p align="center">Cropped Image (100 x 100)</p> </li> <li> <p><strong>Creating Coordinate Map:</strong> A function is defined to create a coordinate map for the original image. The coordinate map consists of coordinates and corresponding to the pixel values of all the three channels (R G B).</p> </li> <li> <p><strong>Training the Linear Model:</strong> Another function is defined to train a linear model on the random Fourier features extracted from the coordinate map after scaling it. The model is trained using mean squared error loss and Adam optimizer.</p> </li> <li> <p><strong>Plotting Original vs. Enhanced Image:</strong> A function is defined to plot the original image and the enhanced image side by side.</p> </li> <li> <strong>Enhancing the Image:</strong> An overall function that takes the original image, number of random Fourier features, sigma (kernel width for RBF sampler), learning rate, and number of epochs as input. It then creates random Fourier features, trains the linear model, and plots the original and enhanced images. <ul> <li> <p>The general equation for the Fourier basis functions can be expressed as follows:</p> <p><strong>For sine basis functions: [ \psi_k(x) = \sin(k \omega x + b_k) ]</strong></p> <p><strong>For cosine basis functions: [ \phi_k(x) = \cos(k \omega x + b_k) ]</strong></p> <p>Where:</p> <ul> <li>( k ) is the frequency index,</li> <li>( \omega ) is the angular frequency,</li> <li>( x ) is the input variable,</li> <li>( b_k ) is a randomly generated phase offset. (\newline)</li> </ul> </li> <li> <p>The bandwidth parameter <strong>( \sigma )</strong> influences the spread or width of the basis functions indirectly through the angular frequency <strong>( \omega )</strong>. Typically, <strong>( \omega = \frac{1}{\sigma} )</strong>. However, the direct inclusion of <strong>( \sigma )</strong> in the equation for Fourier basis functions is less common, as <strong>( \sigma )</strong> primarily affects the kernel function used in kernel methods rather than the basis functions themselves.</p> </li> </ul> </li> <li> <strong>Enhancing the Image for Different Sigmas:</strong> The image is enhanced for different values of sigma for finding the better sigma (kernel width for RBF Sampler, it represents the bandwidth parameter of the fourier basis used for feature mapping), and the enhanced images are stored in a list. <ul> <li>For <strong>( \sigma )</strong> = 0.1</li> </ul> <div align="center"> <img src="./Ques4Img/dog_sigma01.png" alt="dog_img" width="50%"> </div> <ul> <li>For <strong>( \sigma )</strong> = 0.04</li> </ul> <div align="center"> <img src="./Ques4Img/dog_sigma04.png" alt="dog_img" width="50%"> </div> <ul> <li>For <strong>( \sigma )</strong> = 0.001</li> </ul> <div align="center"> <img src="./Ques4Img/dog_sigma001.png" alt="dog_img" width="50%"> </div> <p>As you can see for higher <strong>( \sigma )</strong> values, the model is creating less complex decision boundaries and is not able to capture the fine details of the image. On the other hand, for lower <strong>( \sigma )</strong> values, the model is creating more complex decision boundaries and is able to capture the fine details of the image but further decreasing the <strong>( \sigma )</strong> value will lead to overfitting and the model will not be able to generalize well on the test data. This we can see in the image with <strong>( \sigma )</strong> = 0.001, the model has high variance.</p> </li> <li> <p><strong>Output:</strong> The comparison between the low-resolution image and the enhanced image is displayed for each sigma value. On comparison it is found that the image with the sigma value of around 0.04 gives the best results.</p> <ul> <li>For <strong>( \sigma )</strong> = 0.04</li> </ul> <div align="center"> <img src="./Ques4Img/dog_sigma04.png" alt="dog_img" width="50%"> </div> </li> </ol> <p>The code effectively demonstrates Super-Resolution using a linear model trained on Random Fourier Features. It provides a qualitative comparison between the original and enhanced images, showing how the resolution is improved. Additionally, it allows experimenting with different values of sigma to observe their effects on the enhanced image over different bandwidths of the fourier basis used for feature mapping. We will also see the quantitative analysis in the next part of the question which will allow us to evaluate the performance of the super-resolution technique using RMSE and PSNR.</p> <p><strong>NOTE:</strong> <em>The quality of the output image depends on the choice of sigma (kernel width for RBF sampler) and the number of random Fourier features used, which can be further optimized using Hyperparameter Tuning.</em></p> <h3 id="b-quantitative-analysis">$B.$ Quantitative Analysis</h3> <p>The study can be further improved by adding quantitative analysis to evaluate the performance of the super-resolution technique. This can be done by calculating and comparing metrics such as Root Mean Square Error (RMSE) and Peak Signal-to-Noise Ratio (PSNR) between the Original $N$ x $N$ Image and Enhance $N$ x $N$ Image from $N/2$ x $N/2$ Image. Here is the breakdown of the code:</p> <ol> <li> <p><strong>Original Image (400 x 400):</strong><br> The original image is the cropped image of size 400 x 400 pixels. This serves as the ground truth for comparison.</p> <div align="center"> <img src="./Ques4Img/dog_ground_truth.png" alt="dog_img" width="70%"> </div> <p align="center">Ground Truth Image (400 x 400)</p> </li> <li> <p><strong>Low-Resolution Image (200 x 200):</strong><br> The original image is downsampled using 2D convolution to create a low-resolution image with dimensions of 200 x 200 pixels.</p> <div align="center"> <img src="./Ques4Img/dog_lowres.png" alt="dog_img" width="70%"> </div> <p align="center">Low-Resolution Image (200 x 200)</p> </li> <li> <p><strong>Generating Random Fourier Features:</strong><br> Random Fourier features are generated for the scaled coordinates of the low-resolution image using the RBF Sampler. training a linear model on these features to learn the mapping from low to high resolution.</p> </li> <li> <p><strong>Training the Linear Model on RFF:</strong> The Linear Model has input features equal to the Random Fourier Features and the output features equal to the RGB values of the original image i.e, 3. The model is trained using mean squared error loss and Adam optimizer.</p> </li> <li> <strong>Enhanced Image (400 x 400):</strong><br> The learned model is then applied to the coordinate map of the low-resolution image to generate an enhanced version with dimensions of 400 x 400 pixels. <div align="center"> <img src="./Ques4Img/pred_dog.png" alt="dog_img" width="70%"> </div> <p>[The image here formed is made with the sigma value of 0.03 and number of random Fourier features as 10000. As the 10000 features are not able to represent the data properly, the image is not enhanced properly and is not very comparable to the original image. This can be improved by increasing the number of random Fourier features which requires more computation and memory.]</p> </li> <li> <p><strong>Quantitative Metrics:</strong> The mean squared error (RMSE) and peak signal-to-noise ratio (PSNR) are calculated to quantitatively assess the similarity between the original and enhanced images. These metrics provide objective measures of the quality of the enhancement. The formulas for RMSE and PSNR are as follows:</p> <ul> <li> <p>Root Mean Square Error (RMSE): [ RMSE = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - y_i)^2} ] where ( N ) is the total number of pixels in the image, ( x_i ) is the pixel value of the original image, and ( y_i ) is the pixel value of the enhanced image. We will calculate RMSE for each channel (R, G, B) and then take the sum of the three values.</p> </li> <li> <p>Peak Signal-to-Noise Ratio (PSNR): [ PSNR = 20 \log_{10}\left(\frac{MAX_I}{\sqrt{MSE}}\right) ] where ( MAX_I ) is the maximum possible pixel value (1.0 for scaled pixels values) and ( MSE ) is the mean squared error between the original and enhanced images.</p> </li> </ul> </li> <li> <strong>Output:</strong> The RMSE and PSNR values that we got from the above calculations are as follows: <ul> <li>RMSE: 0.05166782811284065</li> <li>PSNR: 25.73858642578125</li> </ul> <p>The high PSNR value indicates that the enhanced image is very similar to the original image, and the low RMSE value further confirms this. The quantitative analysis provides a more objective evaluation of the super-resolution technique, allowing us to assess the effectiveness of the method in improving image resolution while preserving important features.</p> </li> </ol> <p>Overall, this approach allows for both qualitative and quantitative evaluation of the super-resolution technique. By comparing the original and enhanced images and calculating RMSE and PSNR, it provides insights into the effectiveness of the method in improving image resolution while preserving important features.</p> <h3 id="c-reconstruction-of-the-image">$C.$ Reconstruction of the Image</h3> <p>In this part, we randomly remove data from an image and then reconstruct it using random fourier features and linear regression.</p> <p>The following is the actual image:</p> <div align="center"> <img src="./Ques4Img/dog_ground_truth.png" alt="dog_img" width="70%"> </div> <p>Now, we will randomly remove data from this image and reconstruct it. This image has a size of 400 x 400 pixels. For all the cases below, we use sigma 0.025 (for the RBF sampler) and 10000 random Fourier features.</p> <ol> <li> <p><strong>Remove 90% Data:</strong></p> <p>The image with 90% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog90.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog90p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0786 PSNR: 22.08719840300042</p> </li> <li> <p><strong>Remove 80% Data:</strong></p> <p>The image with 80% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog80.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog80p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0387 PSNR: 28.25418146450278</p> </li> <li> <p><strong>Remove 70% Data:</strong></p> <p>The image with 70% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog70.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog70p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0330 PSNR: 29.63423604352773</p> </li> <li> <p><strong>Remove 60% Data:</strong></p> <p>The image with 60% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog60.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog60p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0309 PSNR: 30.210612612395682</p> </li> <li> <p><strong>Remove 50% Data:</strong></p> <p>The image with 50% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog50.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog50p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0301 PSNR: 30.43539642977963</p> </li> <li> <p><strong>Remove 40% Data:</strong></p> <p>The image with 40% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog40.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog40p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0295 PSNR: 30.596299417410222</p> </li> <li> <p><strong>Remove 30% Data:</strong></p> <p>The image with 30% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog30.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog30p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0292 PSNR: 30.686033211585062</p> </li> <li> <p><strong>Remove 20% Data:</strong></p> <p>The image with 20% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog20.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog20p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0289 PSNR: 30.78619621879038</p> </li> <li> <p><strong>Remove 10% Data:</strong></p> <p>The image with 10% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog10.png" alt="dog_img" width="50%"> </div> <p>The predicted image is:</p> <div align="center"> <img src="./Ques4Img/dog10p.png" alt="dog_img" width="90%"> </div> <p>Root Mean Sqaured Error: 0.0286 PSNR: 30.86548449905607</p> </li> </ol> <h4 id="plots">Plots</h4> <h5 id="rmse-vs-percentage-of-data-removed">RMSE vs Percentage of Data Removed</h5> <p>The following plot shows the RMSE for different percentages of data removed from the image (denoted by x-axis):</p> <div align="center"> <img src="./Ques4Img/rmse.png" alt="dog_img" width="90%"> </div> <h5 id="psnr-vs-percentage-of-data-removed">PSNR vs Percentage of Data Removed</h5> <p>The following plot shows the Peak Signal to Noise Ratio for different percentages of data removed from the image (denoted by x-axis):</p> <div align="center"> <img src="./Ques4Img/psnr.png" alt="dog_img" width="90%"> </div> <h4 id="observations">Observations:</h4> <ol> <li>As we remove data, the rmse value increases as expected. This is because the error (with respect to the original image’s pixel values) increases, as we have less data to train the model.</li> <li>As we remove data, the peak SNR (signal to noise ratio) decreases. This is because now we have more data to train the model on, so the error (which is the noise) decreases.</li> </ol> <p>As we have lesser data to train on, our model cannot capture all the details of the image. We fit features based on data available and extrapolate these over unknown points, thus, we can’t capture all the details, rather, it’s an extrapolated approximation.</p> <p>10000 features have been used because of computational limitations. If the number of features are increased, then the model will be able to capture more details and the reconstructed image will be better.</p> <p>On increasing the value of sigma, the image becomes smoother and the details are not captured properly. On decreasing the value of sigma, the model overfits and the reconstructed image is not good. Thus, the value of sigma should be chosen carefully.</p> <p><strong>Changing sigma:</strong></p> <p>The image with 90% of the data removed is as follows:</p> <div align="center"> <img src="./Ques4Img/dog90.png" alt="dog_img" width="50%"> </div> <p>The predicted image for sigma = 0.025 is:</p> <div align="center"> <img src="./Ques4Img/dog90p.png" alt="dog_img" width="90%"> </div> <p>The predicted image for sigma = 0.03 is:</p> <div align="center"> <img src="./Ques4Img/dog90p2.png" alt="dog_img" width="90%"> </div> <p>&lt;/span&gt;</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/PyCon_proposal">PyCon 2024 Proposal</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/week5">GSoC'24 Week 5</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/week9">GSoC'24 Week 9</a> </li> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> <div class="social"> <div class="contact-icons"> <a href="mailto:%6B%69%73%68%61%6E.%76%65%64@%69%69%74%67%6E.%61%63.%69%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://github.com/Kishan-Ved" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/kishan-ved-506140259" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://wa.me/919619319866" title="whatsapp" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-whatsapp"></i></a> </div> </div> © Copyright 2024 Kishan Ved. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>